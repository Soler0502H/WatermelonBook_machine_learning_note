{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习的定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习是一门学科，致力于研究如何通过计算的手段，利用`经验`来玫善系统自身的性能在计算机系统中，`\"经验\"通常以\"数据\"形式存在`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习所研究的主要内容，是关于在计算机上从数据中产生\"模型\" (model) 的算法，即`\"学习算法\" (learning algorithm)`. 利用学习算法，把经验数据提供给它，就能基于`数据产生模型`;在面对新的情况时(例 如看到一个没剖开的西瓜)，模型会给我们提供相应的判断(例如好瓜) 。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
    ![](https://github.com/SolerHo/WatermelonBook_machine_learning_note/blob/master/notebook/%E7%AC%AC%E4%B8%80%E7%AB%A0/Images/%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%9B%BE.png)
   
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经验就是数据，而机器学习就是让计算机从数据中产生出模型的算法，即学习算法。有了学习算法，我们就可以基于这些数据产生相应的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、机器学习基本术语"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **数据集（Data set）**：所有记录的集合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **一个实例（instance）或样本（example）**：每一条记录是关于一个事件或对象的描述。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **\"属性\" (attribute) 或\"特征\" (feature)**：反映事件或对象在某方面的表现或性质的事项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **属性值**：属性上的取值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 属性张成的空间称为`“属性空间” (attribute space) 、 \"样本空间\" (samp1e space)或\"输入空间\"`。\n",
    "- 空间中的每个点对应一个坐标向量，因此也把一个示例称为一个`\"特征向量\" (feature vector)`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个样本的特征数为`维数（dimensionality）`，当维数`非常大`时，也就是现在说的`“维数灾难”`。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](attachment:https://github.com/SolerHo/WatermelonBook_machine_learning_note/blob/master/notebook/%E7%AC%AC%E4%B8%80%E7%AB%A0/Images/%E6%95%B0%E6%8D%AE%E9%9B%86.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图中d为样本x_i的维数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **“学习”或者是“训练”**：从数据中学得模型的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **训练数据（Training Data）**：训练的过程中使用的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **训练样本（Training Sample）**：训练的每一个记录。有时候训练样本也叫做训练示例或者是训练例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **训练集（Training Set）**：训练样本的集合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **假设（hypothesis）**：学得模型对应了关于数据的某种潜在规律"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **真相（ground-truth）**：数据的潜在规律"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在预测西瓜的例子中，我们预测的是：好瓜和坏瓜，这样子的学习任务就是分类，属于`离散值`。而预测瓜的成熟度，这类型的学习任务称为回归，属于`连续值`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 预测值为离散值的问题为：**分类（classification）**。\n",
    "- 预测值为连续值的问题为：**回归（regression）**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "涉及多个类别时，则称为**“多分类（Multi-class Classification）任务”**。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](attachment:https://github.com/SolerHo/WatermelonBook_machine_learning_note/blob/master/notebook/%E7%AC%AC%E4%B8%80%E7%AB%A0/Images/%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到模型之后，就需要进行预测的过程，此时称为测试，被预测的样本叫做**测试样本（Testing Sample）**。测试样本也叫做**预测示例**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据训练数据`是否有标记信息`，学习任务大致可划分为两大类：**监督学习** 和**无监督学习**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **监督学习（supervised learning）**：在之前提到过的分类和回归就是监督学习的代表。训练数据是有标记信息的。\n",
    "- **无监督学习（unsupervised learning）**：聚类则是无监督学习的代表。训练数据没有标记信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学得模型适用于新样本的能力，称为**泛化（Generalization）能力**。具有强泛化能力的模型能够很好地适用于整个样本空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、假设空间\n",
    "是指所有可能的能满足样本输入和输出的`假设函数h（x）的集合`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设函数一定是一个无穷大的集合。也就是说如果样本是一串有穷的离散点$(x_i,y_i)$,i属于1到N，那么能够拟合这些点的无穷多个函数都是可能的假设函数。\n",
    "\n",
    "**归纳（induction）** 和 **演绎（deduction）** 是科学推理的两大基本手段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**归纳**：从`特殊到一般`的“泛化（generalization）”过程。即从具体的事实归纳出一般性规律。\n",
    "\n",
    "\n",
    "**演绎**：从`一般到特殊`的“特化（specialization）”过程。即从基础原理推演出具体状况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、归纳偏好\n",
    "是一个能挑选出最佳假设函数的基准。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习算法在学习过程中对某种类型假设的偏好，称为**归纳偏好（induction bias）简称为偏好**。\n",
    "\n",
    "任何一个有效的机器学习算法必有一个归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设迷惑，而无法产生确定的学习结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**归纳偏好的作用**：\n",
    "\n",
    "图中的每个训练样本是图中的一个点（x,y）,要学得一个模型与训练集一致的模型，相当于找到一条穿过所有训练样本点的曲线。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](attachment:https://github.com/SolerHo/WatermelonBook_machine_learning_note/blob/master/notebook/%E7%AC%AC%E4%B8%80%E7%AB%A0/Images/%E5%BD%92%E7%BA%B3%E5%81%8F%E5%A5%BD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如图所示来说明：对有限样本点组成的训练集，存在着很多曲线与其一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、NFL定理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NFL定理，No Free Lunch定理。具体含义指: 针对某一域的所有问题，所有算法的期望性能是相同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设一个算法为a，而随机胡猜的算法为b，为了简单起见，假设样本空间为χχ和假设空间为HH都是离散的。令 P(h|X,$L_a$) 表示算法a基于训练数据X产生假设h的概率，再令f代表我们希望的真实目标函数。a的训练集外误差，即a 在训练集之外的所有样本上的误差为:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](attachment:https://github.com/SolerHo/WatermelonBook_machine_learning_note/blob/master/notebook/%E7%AC%AC%E4%B8%80%E7%AB%A0/Images/%E6%A0%B7%E6%9C%AC%E9%9B%86%E7%9A%84%E8%AF%AF%E5%B7%AE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)$x$代表“样本空间”，$H$为“假设空间”，这两者都是离散的。\n",
    "\n",
    "(2)$X$为“训练数据”，故$x-X$的意义是“训练集外”。这是因为算法性能，是通过衡量训练集外误差得到的，即off-training error（ote）。\n",
    "\n",
    "(3)P(h|X,$L_a$) 表示当 $L_a$ 使用算法时，基于训练集X，产生假设h的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑**二分类问题**，且真实目标函数可以是任何函数x-->{0,1},函数空间为{0,1}^|χ|,|χ|指样本空间χχ中元素个数，对所有可能的f按均匀分布对误差求和，有 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](attachment:https://github.com/SolerHo/WatermelonBook_machine_learning_note/blob/master/notebook/%E7%AC%AC%E4%B8%80%E7%AB%A0/Images/EOT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上的结果式子可以发现，总误差和学习算法无关。对于任意的两个学习算法都有 $L_a$ 和 $L_b$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](attachment:https://github.com/SolerHo/WatermelonBook_machine_learning_note/blob/master/notebook/%E7%AC%AC%E4%B8%80%E7%AB%A0/Images/%E6%9C%9F%E6%9C%9B%E6%80%A7%E8%83%BD.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
